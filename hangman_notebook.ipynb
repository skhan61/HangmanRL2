{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demo Notebook\n",
    "- Can play with pretrianed files locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf dist\n",
      "find . -type f -name \"*.DS_Store\" -ls -delete\n",
      "find . | grep -E \"(__pycache__|\\.pyc|\\.pyo)\" | xargs rm -rf\n",
      "find . | grep -E \".pytest_cache\" | xargs rm -rf\n",
      "find . | grep -E \".ipynb_checkpoints\" | xargs rm -rf\n",
      "rm -f .coverage\n"
     ]
    }
   ],
   "source": [
    "! make clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf logs/**\n",
      "rm -rf wandb/**\n"
     ]
    }
   ],
   "source": [
    "! make clean-logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! rm  -rf /media/sayem/510B93E12554BBD1/Hangman/wandb\n",
    "# ! rm -rf /media/sayem/510B93E12554BBD1/checkpoints "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def set_seed(seed):\n",
    "    \"\"\"Set seed for reproducibility.\"\"\"\n",
    "    random.seed(seed)       # Python random module\n",
    "    np.random.seed(seed)    # Numpy module\n",
    "    torch.manual_seed(seed) # PyTorch\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)          # Sets seed for CUDA (GPU)\n",
    "        torch.cuda.manual_seed_all(seed)      # Ensure reproducibility on all GPUs\n",
    "        torch.backends.cudnn.deterministic = True  # Use deterministic algorithms\n",
    "        torch.backends.cudnn.benchmark = False     # If input sizes do not vary, this should be set to False\n",
    "\n",
    "# Example usage: \n",
    "set_seed(42)  # Use any number to seed all libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import read_word_list, read_rnd_word_list\n",
    "from src.data_generation.dataset_analysis import stratified_sample_from_categories, \\\n",
    "    classify_words_by_unique_letter_count, summarize_categories, categorize_words_by_length\n",
    "corpus_path = 'data/words_250000_train.txt' # ## Just a demo, replace with your corpus path\n",
    "total_samples = 250_000  # This can be adjusted as needed\n",
    "\n",
    "# Read a specified number of words from the corpus\n",
    "corpus = read_rnd_word_list(corpus_path, num_samples=total_samples)\n",
    "\n",
    "# classification = categorize_words_by_length(corpus)\n",
    "\n",
    "# summaries = summarize_categories(classification)\n",
    "\n",
    "# corpus = classification[2]\n",
    "# print(len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# # from src.datamodule import HangmanDataset\n",
    "# from src.datamodule import HangmanDataModule\n",
    "import gymnasium as gym\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# torch.set_float32_matmul_precision('high')\n",
    "import lightning as L \n",
    "# # L.seed_everything(102, workers=True)\n",
    "# np.random.seed(102)  # You can use any number here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium.envs.registration import register\n",
    "\n",
    "# Registration code without default kwargs\n",
    "register(\n",
    "    id='Hangman-v0',  # Use an environment ID that follows Gym conventions\n",
    "    entry_point='rl_squared.envs.hangman.hangman_env:HangmanEnv',  # Module and class name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_meta_episodes = 14\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from rl_squared.utils.env_utils import make_vec_envs, make_env_thunk\n",
    "from rl_squared.training.meta_episode_batch import MetaEpisodeBatch\n",
    "from rl_squared.envs.hangman.hangman_env import HangmanEnv\n",
    "import numpy as np\n",
    "from gymnasium.envs.registration import register\n",
    "\n",
    "from rl_squared.networks.stateful.stateful_actor_critic \\\n",
    "                import StatefulActorCritic\n",
    "\n",
    "from rl_squared.envs.hangman.hangman_env import HangmanEnv\n",
    "import numpy as np\n",
    "import copy\n",
    "from rl_squared.networks.modules.distributions import MaskableCategoricalDistribution\n",
    "config = {'word_list': corpus, 'max_attempts': 6, \\\n",
    "        'max_length': 35, 'auto_reset': True,}\n",
    "\n",
    "\n",
    "total_samples = 250_000  # This can be adjusted as needed\n",
    "\n",
    "corpus = read_word_list(corpus_path, num_samples=total_samples)\n",
    "num_meta_episodes = len(corpus)\n",
    "print(f\"num_meta_episodes = {num_meta_episodes}\")\n",
    "num_parallel_envs = 3\n",
    "\n",
    "# Assuming make_vec_envs is a function defined elsewhere that creates vectorized environments\n",
    "rl_squared_envs = make_vec_envs('Hangman-v0', \\\n",
    "                config, 200, num_parallel_envs, 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl_squared.networks.stateful.stateful_actor_critic import StatefulActorCritic\n",
    "from rl_squared.networks.stateful.stateful_actor import StatefulActor\n",
    "from rl_squared.networks.stateful.stateful_critic import StatefulCritic\n",
    "\n",
    "actor_critic = StatefulActorCritic(\n",
    "        rl_squared_envs.observation_space,\n",
    "        rl_squared_envs.action_space,\n",
    "        recurrent_state_size=1024,\n",
    ").to_device('cuda')\n",
    "\n",
    "# actor = StatefulActor(\n",
    "#         observation_space=rl_squared_envs.observation_space,\n",
    "#         action_space=rl_squared_envs.action_space,\n",
    "#         recurrent_state_size=512,\n",
    "#         hidden_sizes=[256],\n",
    "# )\n",
    "\n",
    "# x, recurrent_state = actor(observations, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckt_path = \"results/hangman-v0/run-1725320963/checkpoints/checkpoint-best.pt\"\n",
    "\n",
    "checkpoint = torch.load(ckt_path, map_location='cpu', \\\n",
    "                    weights_only=True)\n",
    "# current_iteration = checkpoint[\"iteration\"]\n",
    "# actor_critic.actor.load_state_dict(checkpoint[\"actor\"])\n",
    "# actor_critic.critic.load_state_dict(checkpoint[\"critic\"])\n",
    "actor_critic.load_state_dict(checkpoint[\"actor_critic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import os\n",
    "# import glob\n",
    "# from collections import OrderedDict\n",
    "\n",
    "# # Define the base directory and pattern for checkpoint files\n",
    "# base_dir = \"./_results/hangman-v0\"\n",
    "# pattern = \"**/*-best.pt\"\n",
    "# search_pattern = os.path.join(base_dir, pattern)\n",
    "\n",
    "# # Find all matching checkpoint files\n",
    "# checkpoint_files = glob.glob(search_pattern, recursive=True)\n",
    "\n",
    "# # Load all the checkpoints with weights_only=True for safety\n",
    "# checkpoints = [torch.load(path, map_location='cpu', \\\n",
    "#                           weights_only=True) for path in checkpoint_files]\n",
    "\n",
    "# def average_checkpoints(checkpoint_list):\n",
    "#     \"\"\"Average the state dictionaries from a list of loaded checkpoints.\"\"\"\n",
    "#     avg_state_dict = OrderedDict()\n",
    "#     # Initialize the average state dictionary with zeros\n",
    "#     for key in checkpoint_list[0]['actor_critic'].keys():\n",
    "#         avg_state_dict[key] = torch.zeros_like(checkpoint_list[0]['actor_critic'][key])\n",
    "#     # Sum all parameters\n",
    "#     for checkpoint in checkpoint_list:\n",
    "#         for key, value in checkpoint['actor_critic'].items():\n",
    "#             avg_state_dict[key] += value\n",
    "#     # Average the parameters\n",
    "#     for key in avg_state_dict.keys():\n",
    "#         avg_state_dict[key] /= len(checkpoint_list)\n",
    "#     return avg_state_dict\n",
    "\n",
    "# # Perform averaging if checkpoints are loaded\n",
    "# if checkpoints:\n",
    "#     avg_state_dict = average_checkpoints(checkpoints)\n",
    "#     # Load the averaged state dictionary into the pre-defined actor-critic model\n",
    "#     actor_critic.load_state_dict(avg_state_dict)\n",
    "#     print(\"Averaged model parameters loaded into the actor-critic model.\")\n",
    "# else:\n",
    "#     print(\"No checkpoints were found or loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_generation.simulation import play_a_game_with_a_word, \\\n",
    "    simulate_games_for_word_list # testing function\n",
    "# from src.data_generation.process_word import process_word\n",
    "# from src.datamodule.dataset import encode_character\n",
    "from src.model.inference import guess #, guess_character\n",
    "from src.data_generation.simulation import play_a_game_with_a_word, \\\n",
    "                            simulate_games_for_word_list # testing function\n",
    "from src.data_generation.data_generation \\\n",
    "    import simulated_guess_function, generate_a_game_with_a_word\n",
    "\n",
    "# solver = HangmanFreqSolver(corpus) # TODO: does it matter waht corpus, \n",
    "# since no use use in guess?\n",
    "# transform = ProcessWordTransform(corpus) # here, what corpus does not matter\n",
    "\n",
    "# Example word\n",
    "# word = 'jazz' \n",
    "# word = 'superacknowledgment'\n",
    "word = 'mississippi' # out of corpus\n",
    "# word = 'embryoplastic' # from corpus\n",
    "# word = \"aandahl\"\n",
    "masked_word = '_' * len(word)\n",
    "# masked_word = ''\n",
    "guessed_letters = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pulmobranchiate', 'senzer', 'quasicomprehensively', 'embryoplastic']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['pulmobranchiate', 'senzer', 'quasicomprehensively', 'embryoplastic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor_critic.recurrent_state_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i\n"
     ]
    }
   ],
   "source": [
    "gussed_character, recurrent_states_actor, recurrent_states_critic \\\n",
    "    = guess(model=actor_critic, \n",
    "            word=masked_word, # TODO\n",
    "            guessed_letters=guessed_letters,\n",
    "            previous_action='a',\n",
    "            recurrent_states_actor=None,\n",
    "            recurrent_states_critic=None)\n",
    "\n",
    "print(gussed_character) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False,\n",
       " 0,\n",
       " [('t', '___________', False),\n",
       "  ('e', '___________', False),\n",
       "  ('i', '_i__i__i__i', True),\n",
       "  ('l', '_i__i__i__i', False),\n",
       "  ('c', '_i__i__i__i', False),\n",
       "  ('n', '_i__i__i__i', False),\n",
       "  ('s', '_ississi__i', True),\n",
       "  ('r', '_ississi__i', False)])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "play_a_game_with_a_word(word=word, \\\n",
    "            guess_function=guess, model=actor_critic) # aggregated_data=None): # TODO: aggregated_data=None: remove later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (False,\n",
    "#  0,\n",
    "#  [('e', '____', False),\n",
    "#   ('a', '_a__', True),\n",
    "#   ('s', '_a__', False),\n",
    "#   ('n', '_a__', False),\n",
    "#   ('t', '_a__', False),\n",
    "#   ('r', '_a__', False),\n",
    "#   ('l', '_a__', False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def read_rnd_word_list(file_path, num_samples=1_000):\n",
    "    with open(file_path, 'r') as file:\n",
    "        words = file.readlines()  # Read all lines from the file\n",
    "        words = [word.strip() for word in words]  # Remove any extra whitespace or newline characters\n",
    "\n",
    "    # Shuffle the list of words to randomize the order\n",
    "    random.shuffle(words)\n",
    "\n",
    "    # Return the first num_samples words if the list is longer than num_samples\n",
    "    return words[:num_samples] if len(words) > num_samples else words\n",
    "\n",
    "# corpus_path_ = '/media/sayem/510B93E12554BBD1/Hangman/data/hidden_words.txt'\n",
    "# selected_words = read_rnd_word_list(corpus_path_, num_samples=110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulating games: 100%|██████████| 14/14 [00:00<00:00, 63.26word/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Statistics:\n",
      "Total Games: 14, Wins: 7, Losses: 7\n",
      "Win Rate: 0.50, Average_tries_remaining: 1.64\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "corpus_path_ = 'data/words_250000_train.txt' ## Just a demo, replace with your corpus path\n",
    "\n",
    "# word_list = read_word_list(corpus_path_, num_samples=110)\n",
    "\n",
    "from src.data_generation.simulation import play_a_game_with_a_word, \\\n",
    "                            simulate_games_for_word_list # testing function\n",
    "\n",
    "# for _ in range(10):\n",
    "selected_words = read_rnd_word_list(corpus_path_, num_samples=250_000)\n",
    "final_results = simulate_games_for_word_list(word_list=selected_words, guess_function=guess, \\\n",
    "                                            play_function=play_a_game_with_a_word, \\\n",
    "                                            model=actor_critic) \n",
    "\n",
    "# Print overall statistics\n",
    "overall_stats = final_results['overall']\n",
    "print(\"\\nOverall Statistics:\") \n",
    "print(f\"Total Games: {overall_stats['total_games']}, Wins: {overall_stats['wins']}, Losses: {overall_stats['losses']}\")\n",
    "print(f\"Win Rate: {overall_stats['win_rate']:.2f}, Average_tries_remaining: {overall_stats['average_tries_remaining']:.2f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'STOP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mSTOP\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'STOP' is not defined"
     ]
    }
   ],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### API Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.api import HangmanAPI\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the file\n",
    "file_path = 'notebooks/api_key.txt'\n",
    "\n",
    "# Use a context manager to open and read the file\n",
    "with open(file_path, 'r') as file:\n",
    "    api_key = file.read().strip()  # Read the content and strip any extra whitespace\n",
    "\n",
    "# print(\"API Key:\", api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = HangmanAPI(model=actor_critic, corpus_path=corpus_path, access_token=api_key, timeout=2_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.start_game(practice=1, verbose=True)\n",
    "[total_practice_runs, total_recorded_runs,total_recorded_successes, total_practice_successes] = api.my_status() # Get my game stats: (# of tries, # of wins)\n",
    "practice_success_rate = total_practice_successes / total_practice_runs\n",
    "print('run %d practice games out of an allotted 100,000. practice success rate so far = %.3f' % (total_practice_runs, practice_success_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev =[total_practice_runs, total_recorded_runs, \\\n",
    "            total_recorded_successes, total_practice_successes] = api.my_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[total_practice_runs, total_recorded_runs, total_recorded_successes, total_practice_successes] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in tqdm(range(1_000)):\n",
    "#     # print('Playing ', i, ' th game')\n",
    "#     # Uncomment the following line to execute your final runs. Do not do this until you are satisfied with your submission\n",
    "#     # api.start_game(practice=0,verbose=False)\n",
    "#     api.start_game(practice=1, verbose=False)\n",
    "#     # DO NOT REMOVE as otherwise the server may lock you out for too high frequency of requests\n",
    "#     time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[total_practice_runs,total_recorded_runs,total_recorded_successes,total_practice_successes] = api.my_status() # Get my game stats: (# of tries, # of wins)\n",
    "practice_success_rate = total_practice_successes / total_practice_runs\n",
    "print('run %d practice games out of an allotted 100,000. practice success rate so far = %.3f' % (total_practice_runs, practice_success_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current =[total_practice_runs, total_recorded_runs, \\\n",
    "            total_recorded_successes, total_practice_successes] = api.my_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing recorded games:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(1000)):\n",
    "    # print('Playing ', i, ' th game')\n",
    "    # Uncomment the following line to execute your final runs. Do not do this until you are satisfied with your submission\n",
    "    api.start_game(practice=0,verbose=False)\n",
    "    \n",
    "    # DO NOT REMOVE as otherwise the server may lock you out for too high frequency of requests\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[total_practice_runs,total_recorded_runs,total_recorded_successes,total_practice_successes] = api.my_status() # Get my game stats: (# of tries, # of wins)\n",
    "success_rate = total_recorded_successes/total_recorded_runs\n",
    "print('overall success rate = %.3f' % success_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
